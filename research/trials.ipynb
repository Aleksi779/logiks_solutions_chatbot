{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35fda348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffdcb424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\Logiks_solutions_chatbot'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ecd9092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"Logiks_solutions_chatbot/logiks_solutions_chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ccdabb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Lenovo\\\\Desktop\\\\Logiks_solutions_chatbot\\\\logiks_solutions_chatbot'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f4439431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5a878bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the PDF file\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "032bb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15338260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "82e1a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text chunks:  19\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "\n",
    "print(\"Length of text chunks: \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0a5c59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8422bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2') #384 dimension\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c94bb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0f371e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"Length: \", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d601e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5d499bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5f5ea4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "18332fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"companychatbot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"companychatbot-zmnjrwu.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"companychatbot\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "84d99179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "23038e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and save the embeddings into Pinecone database\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cc98036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing index   \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "88524f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type='similarity', search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ce053181",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Jobstell?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "90b710ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='337e52bd-7221-4732-9eb1-97a4034b666c', metadata={'author': 'aleksi modebadze', 'creationdate': '2025-02-12T00:15:48+04:00', 'creator': 'Microsoft® Word 2021', 'moddate': '2025-02-12T00:15:48+04:00', 'page': 6.0, 'page_label': '7', 'producer': 'Microsoft® Word 2021', 'source': 'Data\\\\Jobstell_AI_Knowledge.pdf', 'total_pages': 8.0}, page_content='10. Is my data secure on Jobstell? \\nYes, Jobstell takes user privacy and security seriously. All data, including voice recordings and \\nresponses, is stored securely. Jobstell does not share user data with third parties, and users can \\nrequest data deletion by contacting support. \\n11. What languages does Jobstell support? \\nCurrently, Jobstell supports English. Future plans include expanding language support, but as of \\nnow, the platform is focused on English language learners.'),\n",
       " Document(id='abeba6b3-f1ec-4349-98e5-a3b454ef7775', metadata={'author': 'aleksi modebadze', 'creationdate': '2025-02-12T00:15:48+04:00', 'creator': 'Microsoft® Word 2021', 'moddate': '2025-02-12T00:15:48+04:00', 'page': 5.0, 'page_label': '6', 'producer': 'Microsoft® Word 2021', 'source': 'Data\\\\Jobstell_AI_Knowledge.pdf', 'total_pages': 8.0}, page_content='Future Roadmap \\n• Expand language support. \\n• Develop a mobile application. \\n• Enhance AI personalization. \\n• Explore recruiter partnerships. \\nLimitations \\n• Currently web-based only (no mobile app yet). \\n• Supports only the English language.\\n \\nFrequently Asked Questions (FAQ) \\n1. What is Jobstell? \\nJobstell is an AI-powered interview preparation platform designed to help job seekers, \\nprofessionals, and English learners prepare for interviews. It provides real-life simulations, \\npersonalized feedback, AI voice agents for English communication practice, and role-playing \\nscenarios to enhance interview readiness. \\n2. How does the interview simulation work? \\nThe interview simulation mimics real-world conditions and helps users practice their responses'),\n",
       " Document(id='e0f3ede4-a5ab-41e3-a9fe-c5d8dc034e97', metadata={'author': 'aleksi modebadze', 'creationdate': '2025-02-12T00:15:48+04:00', 'creator': 'Microsoft® Word 2021', 'moddate': '2025-02-12T00:15:48+04:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word 2021', 'source': 'Data\\\\Jobstell_AI_Knowledge.pdf', 'total_pages': 8.0}, page_content='Jobstell: AI-Powered Interview Preparation Platform \\n \\nCompany Overview \\nJobstell is an innovative AI-powered platform designed to revolutionize interview preparation \\nfor job seekers, professionals, and English learners. By leveraging advanced artificial \\nintelligence, the platform provides a comprehensive, personalized approach to interview \\nreadiness. \\nMission Statement \\nAt Jobstell, our mission is to empower job seekers and professionals by providing personalized \\ninterview preparation, real-time feedback, and targeted study materials. Through AI-driven \\nsimulations and voice assistants, we help users practice English communication skills, improve \\ngrammar, and engage in real-life role-play scenarios. Our platform prepares users emotionally,')]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f99b5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature=0.4,\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7763581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks about the company. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e10e7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "77b72cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not contain information about Hitler. If you need information about Jobstell or its services, please let me know.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"who is hitler?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
